{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from magenta.models.nsynth import utils\n",
    "from magenta.models.nsynth.wavenet import fastgen\n",
    "from magenta.models.nsynth.wavenet.h512_bo16 import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '/mnt/data/Birdman/models/wavenet-ckpt/model.ckpt-200000'\n",
    "sample_size = 32000\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window, overlap, copy = False):\n",
    "    sh = (a.size - window + 1, window)\n",
    "    st = a.strides * 2\n",
    "    view = np.lib.stride_tricks.as_strided(a, strides = st, shape = sh)[0::overlap]\n",
    "    if copy:\n",
    "        return view.copy()\n",
    "    else:\n",
    "        return view\n",
    "    \n",
    "def batch_array(a, batch_len):\n",
    "    idx = list(range(0, len(a), batch_len))\n",
    "    if idx[-1] != len(a):\n",
    "        idx += [len(a)]\n",
    "    for start, end in zip(idx[:-1], idx[1:]):\n",
    "        yield a[start:end]\n",
    "        \n",
    "def load_nsynth(batch_size=1, sample_length=64000):\n",
    "    \"\"\"Load the NSynth autoencoder network.\n",
    "    Args:\n",
    "    batch_size: Batch size number of observations to process. [1]\n",
    "    sample_length: Number of samples in the input audio. [64000]\n",
    "    Returns:\n",
    "    graph: The network as a dict with input placeholder in {\"X\"}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        x = tf.placeholder(tf.float32, shape=[batch_size, sample_length])\n",
    "        graph = config.build({\"wav\": x}, is_training=False)\n",
    "        graph.update({\"X\": x})\n",
    "    return graph\n",
    "\n",
    "def encode(wav_data, checkpoint_path, sample_length=64000):\n",
    "    if wav_data.ndim == 1:\n",
    "        wav_data = np.expand_dims(wav_data, 0)\n",
    "        batch_size = 1\n",
    "    elif wav_data.ndim == 2:\n",
    "        batch_size = wav_data.shape[0]\n",
    "\n",
    "  # Load up the model for encoding and find the encoding of \"wav_data\"\n",
    "    session_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    session_config.gpu_options.allow_growth = True\n",
    "    with tf.Graph().as_default(), tf.Session(config=session_config) as sess:\n",
    "        hop_length = Config().ae_hop_length\n",
    "        wav_data, sample_length = utils.trim_for_encoding(wav_data, sample_length,\n",
    "                                                          hop_length)\n",
    "        print(sample_length)\n",
    "        net = load_nsynth(batch_size=batch_size, sample_length=sample_length)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        encodings = sess.run(net[\"encoding\"], feed_dict={net[\"X\"]: wav_data})\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "session_config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=session_config)\n",
    "net = load_nsynth(batch_size=50, sample_length=31744)\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = []\n",
    "\n",
    "y, sr = librosa.load('/mnt/data/Birdman/samples/recordings/STHELENA-02_20140605_200000_1.wav', sr=None)\n",
    "multiple_sampsize = len(y) // 32000 * 32000\n",
    "y = y[:multiple_sampsize]\n",
    "samples = rolling_window(y, sample_size, sample_size // 2)\n",
    "for sample in batch_array(samples, batch_size):\n",
    "    sample, sample_length = utils.trim_for_encoding(sample, sample_size, Config().ae_hop_length)\n",
    "    encoding = sess.run(net[\"encoding\"], feed_dict={net[\"X\"]: sample[:31744]})\n",
    "    encodings.append(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_subset = samples[:50,:]\n",
    "samples_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = fastgen.encode(wav_data=samples_subset, checkpoint_path=model_path, sample_length=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Config().ae_hop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y, sr = librosa.load('/mnt/data/Birdman/samples/recordings/STHELENA-02_20140605_200000_1.wav', sr=None)\n",
    "samples = rolling_window(y, sample_size, sample_size // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data, sample_length = utils.trim_for_encoding(samples[:50], sample_size, Config().ae_hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(y) / 32000) * 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y) // 32000 * 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
